{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, StorageContext, ServiceContext, VectorStoreIndex, load_index_from_storage\n",
    "from llama_index.core.callbacks.base import CallbackManager\n",
    "# from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "from llama_index.embeddings.cohere import CohereEmbedding\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import chainlit as cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(input_files=[f\".\\\\documents\\\\coe_demo\\\\data-science-lifecycle-ebook.pdf\"])\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:39 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Parsing nodes:   8%|▊         | 1/12 [00:00<00:06,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:40 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 7/7 [00:00<00:00,  7.49it/s]\n",
      "Parsing nodes:  17%|█▋        | 2/12 [00:01<00:08,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:41 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 7/7 [00:00<00:00,  7.09it/s]\n",
      "Parsing nodes:  25%|██▌       | 3/12 [00:02<00:08,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:42 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:43 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:44 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:46 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 38/38 [00:05<00:00,  7.23it/s]\n",
      "Parsing nodes:  33%|███▎      | 4/12 [00:07<00:21,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:47 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 10/10 [00:01<00:00,  8.01it/s]\n",
      "Parsing nodes:  42%|████▏     | 5/12 [00:09<00:15,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:48 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:50 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:51 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:52 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 32/32 [00:03<00:00,  8.26it/s]\n",
      "Parsing nodes:  50%|█████     | 6/12 [00:13<00:16,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:52 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:54 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 15/15 [00:01<00:00,  7.50it/s]\n",
      "Parsing nodes:  58%|█████▊    | 7/12 [00:15<00:12,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:55 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:56 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 13/13 [00:02<00:00,  6.26it/s]\n",
      "Parsing nodes:  67%|██████▋   | 8/12 [00:17<00:09,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:56 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:58 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:58 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 21/21 [00:02<00:00,  8.61it/s]\n",
      "Parsing nodes:  75%|███████▌  | 9/12 [00:19<00:07,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:50:59 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:51:00 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:51:01 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 23/23 [00:02<00:00,  8.45it/s]\n",
      "Parsing nodes:  83%|████████▎ | 10/12 [00:22<00:05,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:51:02 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.84it/s]\n",
      "Parsing nodes:  92%|█████████▏| 11/12 [00:23<00:02,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:51:03 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:51:04 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 15/15 [00:02<00:00,  7.15it/s]\n",
      "Parsing nodes: 100%|██████████| 12/12 [00:25<00:00,  2.12s/it]\n"
     ]
    }
   ],
   "source": [
    "# embed_model = GeminiEmbedding(\n",
    "#     model_name=\"models/embedding-001\", api_key=GOOGLE_API_KEY\n",
    "# )\n",
    "\n",
    "embed_model = CohereEmbedding(\n",
    "    cohere_api_key=COHERE_API_KEY,\n",
    "        model_name=\"embed-english-v3.0\",\n",
    "        input_type=\"search_document\" # \"search_query\", \"search_document\"\n",
    "    )\n",
    "\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1, \n",
    "    breakpoint_percentile_threshold=95, \n",
    "    embed_model=embed_model\n",
    ")\n",
    "nodes = splitter.get_nodes_from_documents(documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Groq(model=\"mixtral-8x7b-32768\", api_key=GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tempdir\\ipykernel_27096\\59880135.py:1: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=llm)\n"
     ]
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 12/12 [00:00<00:00, 238.34it/s]\n",
      "Generating embeddings:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:53:20 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  83%|████████▎ | 10/12 [00:01<00:00,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:53:21 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 12/12 [00:01<00:00,  6.21it/s]\n"
     ]
    }
   ],
   "source": [
    "vector_index = VectorStoreIndex.from_documents(documents, show_progress=True, \n",
    "               service_context=service_context, node_parser=nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index.storage_context.persist(persist_dir=\"./storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@cl.on_chat_start\n",
    "async def factory():\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
    "\n",
    "    # embed_model = GeminiEmbedding(\n",
    "    #     model_name=\"models/embedding-001\", api_key=GOOGLE_API_KEY\n",
    "    # ) \n",
    "\n",
    "    embed_model = CohereEmbedding(\n",
    "    cohere_api_key=COHERE_API_KEY,\n",
    "        model_name=\"embed-english-v3.0\",\n",
    "        input_type=\"search_document\" # \"search_query\", \"search_document\"\n",
    "    )\n",
    "\n",
    "\n",
    "    llm = Groq(model=\"mixtral-8x7b-32768\", api_key=GROQ_API_KEY)\n",
    "\n",
    "    service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=llm,\n",
    "                        callback_manager=CallbackManager([cl.LlamaIndexCallbackHandler()]),\n",
    "    )\n",
    "    cohere_rerank = CohereRerank(api_key=COHERE_API_KEY, top_n=2)\n",
    "\n",
    "    index = load_index_from_storage(storage_context, service_context=service_context)\n",
    "\n",
    "    query_engine = index.as_query_engine(\n",
    "        service_context=service_context,\n",
    "        similarity_top_k=10,\n",
    "        node_postprocessors=[cohere_rerank],\n",
    "        # streaming=True,\n",
    "    )\n",
    "\n",
    "    cl.user_session.set(\"query_engine\", query_engine)\n",
    "\n",
    "@cl.on_message\n",
    "async def main(message: cl.Message):\n",
    "    query_engine = cl.user_session.get(\"query_engine\")  \n",
    "    response = await cl.make_async(query_engine.query)(message.content)\n",
    "\n",
    "    response_message = cl.Message(content=\"\")\n",
    "\n",
    "    for token in response.response:\n",
    "        await response_message.stream_token(token=token)\n",
    "\n",
    "    # if response.response_txt:\n",
    "    #     response_message.content = response.response_txt\n",
    "\n",
    "    await response_message.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:54:48 - Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "index = load_index_from_storage(storage_context, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_rerank = CohereRerank(api_key=COHERE_API_KEY, top_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(service_context=service_context,\n",
    "                similarity_top_k=10,\n",
    "                node_postprocessors=[cohere_rerank],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 11:55:42 - HTTP Request: POST https://api.cohere.ai/v1/embed \"HTTP/1.1 200 OK\"\n",
      "2024-05-20 11:55:43 - HTTP Request: POST https://api.cohere.ai/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "2024-05-20 11:55:45 - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"What is difference between data access and data preparation?\"\n",
    "resp = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data access refers to the process of obtaining raw data from various sources, while data preparation involves cleaning, processing, and understanding the raw data in preparation for analysis and modeling. Data access is concerned with gathering and making available the necessary data for a specific task, while data preparation focuses on transforming and transforming the data into a usable format for further analysis. Data preparation includes tasks such as data cleansing, data exploration, visualization, and transforming data into a suitable format for modeling.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condarag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
